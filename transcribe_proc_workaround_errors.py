"""
This file differs from the transcribe_proc as it will attempt a fix for crashes caused on the AI end. 
We only know work-arounds for some error types, as they are discovered they should be added here.
"""
import math
from time import sleep
import batchalign as ba
from tkinter import messagebox
import os
import subprocess
import sys
import json
import traceback
from types import FunctionType
from huggingface_hub.hf_api import repo_exists as is_valid_model_id
import pycountry
import soundfile
# from CustomAiEngine import CustomAiEngine

DEBUG_MODE = True

DEBUG_LINE_PREFIX = "@DEBUG"
DEBUG_PREAMBLE = "\n".join([f"{DEBUG_LINE_PREFIX} {line}" for line in [
        ('-' * 10 + ' DEBUG LOGS ' + '-' * 10),
        f'The following block of {DEBUG_LINE_PREFIX} lines are autogenerated by the transcriber application.',
        f'If all steps are SUCCESSFUL, then no errors occurred.',
        f'If a debug step line is followed by a bunch of seemingly gibberish, then it is the error message for what went wrong.',
        f'You may remove the {DEBUG_LINE_PREFIX} lines if you wish, but if you are reporting an error to the maintainer, please include these lines.',
        ('-' * 10 + ' DEBUG LOGS ' + '-' * 10),
    ]])

def debug_get_version() -> str:
    """
    Returns: a version string for the active transcriber (will also tell us if the user has changed any files)
    """
    commit_hash = subprocess.check_output(['git', '-C', os.path.dirname(__file__), 'rev-parse', 'HEAD']).decode('ascii').strip()
    diffs = ", ".join([f'*{fn}' for fn in subprocess.check_output(['git', '-C', os.path.dirname(__file__), 'diff', '--name-only']).decode('ascii').strip().replace('\r\n','\n').split('\n')])
    return f'{commit_hash} | {diffs}'

def open_file(file_path):
    # this process is blocking so we dont do it for now so that we can run through the rest of the files given by the UI component
    try:
        # win & mac
        subprocess.call(["open", file_path])
    except:
        try:
            # Linux
            subprocess.call(["xdg-open", file_path])
        except:
            try:
                # win
                os.startfile(file_path)
            except:
                print(f"READY TO OPEN FILE: {file_path}", flush=True)

def spawn_popup_activity(title, message, yes=None, no=None):
    result = messagebox.askyesno(title=title, message=message)
    if result and yes and type(yes) == FunctionType:
        return yes()
    elif not result and no and type(no) == FunctionType:
        return no()


def transcribe_file(input_file, model_name=None, num_speakers=2, lang="eng", open_after=True):
    """Transcribe a file with the given arguments

    Args:
        input_file (str): File path for input.
        model_name (str, optional): ai model name from huggingface. Defaults to None.
        num_speakers (int, optional): number of speakers for diarzation. Defaults to 2.
        lang (str, optional): language code to optimize for - tbh not sure if this actually does anything. Defaults to "eng".
    """
    debug_logs = []
    debug_logs.append(f"Transcriber version: {debug_get_version()}")
    debug_logs.append(f"Args: {input_file} {model_name} {num_speakers} {lang}")

    try:
        num_speakers = int(num_speakers)
    except:
        num_speakers = 2
    try:
        lang = pycountry.languages.lookup(lang).alpha_3
    except:
        lang = 'eng'
    # transcribe
    # whisper = CustomAiEngine(model=model_name, lang=lang)
    whisper = ba.WhisperEngine(model=model_name, lang=lang)

    # split by speaker
    diarization = ba.NemoSpeakerEngine(num_speakers=num_speakers)

    # recognize pauses
    disfluency = ba.DisfluencyReplacementEngine()

    # retrace for verbal backtracking/repetition
    retrace = ba.NgramRetraceEngine()
    
    # morphotag to get %mor %gra etc.
    morphosyntax = ba.StanzaEngine()

    # align
    utr = ba.WhisperUTREngine()
    fa = ba.Wave2VecFAEngine()

    pipeline_activity = [action for action in [
        # README: this is the pipeline that is actually run, 
        # comment out each line for what you want to be run or not
        # @todo: make this a text config file?
        whisper,
        diarization if num_speakers > 1 else None,
        disfluency,
        retrace,  # uncertain how this benefits us
        # morphosyntax,
        utr,
        fa
    ] if action]
    
    n = 0
    output_file = f"{input_file}{'_'+str(n) if n > 0 else ''}.cha"
    while 1:
        output_file = f"{input_file}{'_'+str(n) if n > 0 else ''}.cha"
        if not os.path.exists(output_file):
            break
        n += 1
    doc = ba.Document.new(media_path=input_file, lang=lang)
    for idx, activity in enumerate(pipeline_activity, start=1):
        step_status = ["Started"]
        nlp = ba.BatchalignPipeline(activity)
        try:
            print(f"{input_file} - starting pipeline action: {idx}/{len(pipeline_activity)} - {(type(activity).__name__).replace('Engine','')}")
            doc = nlp(doc)
            chat = ba.CHATFile(doc=doc)
            chat.write(output_file, write_wor=False)
            step_status = ["SUCCESSFUL"]
        except Exception as e:
            step_status = traceback.format_exc().split("\n")
            print(f"{input_file} had an error on step: {idx}/{len(pipeline_activity)} - {(type(activity).__name__).replace('Engine','')}")
            traceback.print_exc()

            # begin non barebones
            # using the soundfile LibsndfileError is not required if you want to run bare-bones
            if isinstance(e, soundfile.LibsndfileError):
                step_status.append("The input file type is not supported! Please convert the file type manually and try again!")
            if type(activity).__name__ == "Whisper" and type(e).__name__ == 'TypeError':
                # WORKAROUND: for the error where we get TypeError: '<=' not supported between instances of 'NoneType' and 'number' errors during the Whisper process, 
                # we can sometimes workaround it by splitting the file and re-running on the split sections (recursively).
                output_file = split_audio_file_and_retry(input_file, model_name, num_speakers, lang)
                step_status.append("An unexpected error occured while transcribing this file. A potential work-around is to re-run the transcriber on the split files and join them automatically.")
                # @todo in the future, for the diarized speakers, change from Speaker 1,2, etc to Speaker A,B... so that a user can find and replace easier.
                step_status += [
                    "Transcribed files after splitting into multiple files! Some errors to expect include: ",
                    " - The diaritized speakers getting mixed up between files.",
                    " - Some words at the start or end of a split file may be repeated.",
                    " - Some segments of the original input file may have failed entirely and need to be transcribed by hand.",
                ]
                break
            # end non barebones
            
        
        for i, line in enumerate(step_status, start=1):
            debug_logs.append(f"Step {idx}/{len(pipeline_activity)} - {(type(activity).__name__).replace('Engine','')} - {i}/{len(step_status)} - {line}")

        print(f"Step {idx}/{len(pipeline_activity)} - {(type(activity).__name__).replace('Engine','')}\n" + "\n".join(step_status))

    if DEBUG_MODE:
        with open(output_file,'a',encoding='utf-8') as f:
            f.write(f"\n{DEBUG_PREAMBLE}\n")
            f.write("\n".join([f"{DEBUG_LINE_PREFIX} {line}" for line in debug_logs]))
    print(f"Completed transcription for {input_file}! The output file can be found directly next to the input file in your file system with a '.cha' file extension: {output_file}", flush=True)
    # uncomment this next block if you want the output file to automatically open
    # return spawn_popup_activity(title="COMPLETED!",message=f"Completed transcription of\n{input_file}\nOutput file can be found here:\n{output_file}\nOpen file now?", yes=lambda: open_file(output_file))
    if open_after:
        open_file(output_file)
    return output_file, debug_logs

def split_audio_file(input_file, intended_num_sections=2, min_audio_segment_length_sec=20, max_audio_segment_length_sec=60*5, overlap_sec=1):
    """Split an audio file into sections with upper and lower bounds for sizes. 
    NOTE this will not overwrite existing files.
    Args:
        input_file (str): input file path
        intended_num_sections (int, optional): number of sections to split into. Defaults to 2.
        min_audio_segment_length_sec (int, optional): min seconds for a split section. Defaults to 20.
        max_audio_segment_length_sec (_type_, optional): max seconds for a split section. Defaults to 60*5.

    Returns:
        List[str]: list of split output files (empty array means files failed to split or it was too short to split)
    """
    total_duration_seconds = soundfile.info(input_file).duration
    if total_duration_seconds < min_audio_segment_length_sec:
        # too small, we dont bother splitting, this will result in requireing manual
        return []
    chunk_duration_seconds = math.ceil(total_duration_seconds / intended_num_sections)
    if chunk_duration_seconds > max_audio_segment_length_sec:
        # too large, cap it at some max length so that we dont end up crashing at the last second and wasting so much time
        chunk_duration_seconds = max_audio_segment_length_sec

    num_chunks = math.ceil(total_duration_seconds / chunk_duration_seconds)

    fn, ext = os.path.basename(input_file).rsplit(".",1)

    output_file_name_template = os.path.join(os.path.pardir(input_file), fn + "_{}." + ext)
    output_fns = []
    for i in range(num_chunks):
        start_time_seconds = i * chunk_duration_seconds
        # dont overwrite existing files in case somehow they werent made by us
        j = 0
        while os.path.exists(output_file_name_template.format(f"{i+j+1:0>4}")):
            j += 1
        
        out_fn = output_file_name_template.format(f"{i+j+1:0>4}")
        output_fns.append(out_fn)
        command = [
            'ffmpeg',
            '-ss', math.max(start_time_seconds - overlap_sec, 0),
            '-i', input_file,
            '-t', (chunk_duration_seconds + (overlap_sec * (1 if i == 0 else 2))),
            '-c', 'copy',  # Copy streams without re-encoding for speed
            out_fn
        ]
        try:
            subprocess.run(command, check=True, capture_output=True, text=True)
        except subprocess.CalledProcessError as e:
            print(f"FFmpeg error occurred while attempting to split your file: {e}")
            print(f"FFmpeg command: {' '.join(e.cmd)}")
            print(f"FFmpeg stdout: {e.stdout}")
            print(f"FFmpeg stderr: {e.stderr}")
        except Exception as e:
            print(f"An unexpected error occurred while attempting to split your file: {e}")
        
    return output_fns

def split_audio_file_and_retry(input_file, model_name, num_speakers, lang, open_after=False):
    """
    This solution is to split the audio file into sections and re-run the transcriber on each split section, 
        afterwards it will re-join the results into a single .cha file.
    """
    intended_num_sections = 2
    min_audio_segment_length_sec = 20
    max_audio_segment_length_sec = 60 * 20
    debug_logs = []
    debug_logs.append(f"Transcriber version: {debug_get_version()}")
    debug_logs.append(f"Args: {input_file} {model_name} {num_speakers} {lang}")
    
    debug_logs.append(f"Started with input file: {input_file}")
    # STEP 1: Split audio files!
    split_files = split_audio_file(input_file, 
                                   intended_num_sections=intended_num_sections, 
                                   min_audio_segment_length_sec=min_audio_segment_length_sec, 
                                   max_audio_segment_length_sec=max_audio_segment_length_sec)
    if not split_files:
        return ValueError("Unable to split the input file!")
    file_status = []
    for i,fn in enumerate(split_files):
        debug_logs.append(f"split file #{i}/{len(split_files)}: {fn}")
    
    # Step 2: Transcribe
    for i, fn in enumerate(split_files, start=1):
        debug_logs.append(f"split file: {fn}")
        status = {"status": "STARTED", "order": i, "src": fn, 'out':None, 'err': None}
        
        try:
            # DO TRANSCRIBE
            output_file = transcribe_file(fn, model_name=model_name, num_speakers=num_speakers, lang=lang, open_after=False)
            status['out'] = output_file
            status['status'] = 'SUCCESS'
        except Exception as e:
            print(f'Error transcribing "{fn}"', traceback.format_exc())
            status['status'] = 'ERROR'
            status['err'] = traceback.format_exc()
        
        file_status.append(status)
        
    combined_lines = []
    # Step 3: Combine output files
    for file_state in sorted(file_status, key=lambda l: file_status[l]['order']):
        if os.path.exists(file_state['out']):
            with open(file_state, 'r', encoding='utf-8') as f:
                combined_lines += f.readlines()
        if file_state['err']:
            if not os.path.exists(file_state['out']):
                combined_lines += ["@Begin",f"@Media: {file_state['src']}, audio, unlinked"]
            combined_lines += [
                f"{DEBUG_LINE_PREFIX} The following error occured while attempting to transcribe {file_state['src']}.",
                *[f"{DEBUG_LINE_PREFIX} {l}" for l in file_state['err'].split('\n')],
                "",
                "",
                f"@TODO: Please manually transcribe for the audio file: {file_state['src']}"
                ""
                ]
            if not os.path.exists(output_file['out']):
                combined_lines += ["@End"]
    
    n = 0
    combined_output_file = f"{input_file}{'_'+str(n) if n > 0 else ''}.cha"
    while 1:
        combined_output_file = f"{input_file}{'_'+str(n) if n > 0 else ''}.cha"
        if not os.path.exists(combined_output_file):
            break
        n += 1
    chat = ba.CHATFile(lines=combined_lines)
    chat.write(combined_output_file, write_wor=False)
    print(f"Final output file after splitting {input_file}: {combined_output_file}")
    if open_after:
        open_file(combined_output_file)

if __name__ == "__main__":
    print(sys.argv, flush=True)
    for data in sys.argv[1:]:
        try:
            args = json.loads(data)
        except:
            print(f"Failed to parse input data: {data}")
            continue
        print("Attempting to transcribe for:", args.get('input_file',args), flush=True)
        transcribe_file(**args)
        print("Attempt completed for:", sys.argv[1:], flush=True)
