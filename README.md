# Jaffe-Lurie Transcribble
### An offline user friendly transcription tool
- Uses various [`openai-whisper`](https://github.com/openai/whisper) based models to transcribe audio or video files.
- Runs locally.
- Outputs into a clean .cha file by utterance.
- As always, TRUST NOTHING GENERATED BY AI, and always verify

## Requirements:
- if you can, use cuda. (you need NVIDA GPU) https://pytorch.org/get-started/locally/ _do this before running the pip install requirements_
- Python 3.11+ reccomended _(tested on 3.11 and 3.12)_
- internet (for model download, on the first time you use it)
- if on MacOS/Linux, install ffmpeg to be made available by the command line
    - MacOS: `brew install ffmpeg`
- Python tkinter needs to be installed
    - Windows: use the default Python installer and select the tk option
    - MacOS: `brew install python-tk`


---
# How to use:
1. install requirements
    - `pip install -r requirements.txt`
    - if the pip install fails try this:
        - `pip install -r explicit_requirements.txt --no-cache`
    - If you have a CUDA compatible GPU: 
        - [Install CUDA](https://docs.nvidia.com/cuda/cuda-quick-start-guide/)
        - You may need to `pip uninstall torch torchaudio torchvision` before doing this next step.
        - [Reinstall torch torchaudio and torchvision with your appropriate build](https://pytorch.org/get-started/locally/)
            - e.g. if you have cuda 12.6 you would run: `pip install torch torchvision torchaudio --no-cache -U --index-url https://download.pytorch.org/whl/cu126`
    - Otherwise if you dont have a CUDA compatible GPU or dont know what that means then run the next line:
        - `pip install torch torchaudio torchvision`
1. If on windows: 
    - Enable symbolic links on your machine
    - Open the Local group policy editor and add your account user to the following:
    ![Follow these steps](docs\readme_add_symlinks.png)
1. Put your [Huggingface token](https://huggingface.co/docs/hub/en/security-tokens) in a file named `.hftoken`. (Note that it does not need any special permissions, you can deselect all of the options.)
1. Start application.
    - `python ./main.py`
1. Select files (button) to be transcribed.
    - Set the number of speakers in the number box.
    - Set the language (if not english).
1. Select AI model to use from the drop down.
    - Hover over the drop down to see some selection guidance. Choose one that your device can handle.
    - [Read more about the models here.](https://github.com/openai/whisper?tab=readme-ov-file#available-models-and-languages)
4. Start transcript (button).
5. Wait for final results popup to appear.
6. Review resulting transcripts.
---

# Citation

Please see the [CITATION](CITATION.cff) file for citing this work.

> Jaffe, N., & Lurie, S. (2025). *Jaffe-Lurie Transcribble* [Computer software]. GitHub. https://github.com/Noah-Jaffe/Transcribble

---
### Backlog ideas:
- [ ] Advanced/Runtime configuration of AI parameters?
- [ ] Bundle into single executable to be more user friendly?
- [ ] Select subframe of time to transcribe from?

If we use huggingface:
see here for enabling symbolic links:
`gpedit.msc` -> 
![alt text](docs\readme_hf_allow_symlink.png)
@todo show how you can add yourself to create symbolic links


